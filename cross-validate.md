\hspace*{2em}Cross validation is a model validation method that can give an indication of how well the learner will do when it is asked to make new predictions for unknown data. The simplest kind of cross-validation is the holdout method that divide the data set into two sets, called the training set and the test set. The model build its function by using training set only, and errors it makes predicting test set data are accumulated to evaluate the model. The advantage of this method is that it takes no longer to compute. However, the evaluation may be significantly different depending on how the division is made. \textit{K}-fold cross-validation improve over the holdout method by dividing the data set into k subsets and repeating the holdout method \textit{k} times. Each time, one of the \textit{k} subsets is used as test set and the other \textit{k-1} subsets are put together to form a training set. Then the average error across all \textit{k} trials is computed and this is the advantage of \textit{k}-fold cross-validation that it matters less how the data set gets divided.

\hspace*{2em}The available methods introduced above can produce \textit{de novo} prediction of motifs or significant match of known motifs. Partial comparison and clustering of those predictions can also be achieved. However, a statistic validation of motifs to sort prediction results into meaningful, solid motifs has not yet been introduced. Here, we seek to develop a workflow by using 10-fold cross validation to produce validated motifs with biological significance.
